#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sun Mar 15 15:27:58 2020

@author: michelsmacbookpro
"""

import numpy as np
import pickle
import gzip
import random as rd
import matplotlib.pyplot as plt
import os

#import os
#os.chdir('/Users/michelsmacbookpro/Library/Mobile Documents/com~apple~CloudDocs/Written-Calculator//MNIST/data/')

def data_processing(data):
    N_data_train = data[0].shape[0]
    x_processed = [None]*N_data_train
    y_processed = [None]*N_data_train
    for i in range(0,N_data_train):
        x_processed[i] = np.reshape(data[0][i],(len(data[0][i]),1))
        y_processed[i] = np.reshape(data[1][i],(1,1))
        print(str(i+1) + "/" + str(N_data_train))
    return x_processed, y_processed

def data_MNIST_vectorize(y_input):
    N_input = len(y_input)
    y_output = [None]*N_input
    for i in range(0,N_input):
        y_curr_vec = np.zeros((10,1))
        y_curr_vec[int(y_input[i][0][0])] = 1
        y_output[i] = y_curr_vec
        print(str(i+1) + "/" + str(N_input))
    return y_output
    
def data_load(): #Loading of MNIST dataset
    data_file = gzip.open('/Users/michelsmacbookpro/Library/Mobile Documents/com~apple~CloudDocs/Written-Calculator/MNIST/data/mnist.pkl.gz','rb')
    data_file_encoded = pickle._Unpickler(data_file)
    data_file_encoded.encoding = 'latin1'
    data_training, data_validation, data_test = data_file_encoded.load()
    data_file.close()
    return data_training, data_validation, data_test

def feedforward(x_input,i_layer = 0):
    if i_layer == 0:
        i_layer = N_layer-1
    a = x_input
    for i in range(1,i_layer+1):
        a = sigma(np.dot(W_list[i],a)+b_list[i])
    return a

def back_prop(x,y):
    delta_list = [None]*N_layer
    a_list = [None]*N_layer
    nabla_b_C_list = [None]*N_layer
    nabla_W_C_list = [None]*N_layer
    a_L = feedforward(x,N_layer-1)
    a_list[N_layer-1] = a_L
    delta_list[N_layer-1] = (a_L-y)*(a_L-a_L**2)
    
    a_list[0] = x
    for i in range(2,N_layer):
        a = feedforward(x,N_layer-i)
        a_list[N_layer-i] = a 
        delta_list[N_layer-i] = np.dot(W_list[N_layer-i+1].transpose(),delta_list[N_layer-i+1])*(a-a**2)

    for l in range(1,N_layer):
        nabla_b_C_list[l] = delta_list[l]
        nabla_W_C_list[l] = np.zeros(W_list[l].shape)
        for k in range(0,nabla_W_C_list[l].shape[0]):
            for j in range(0,nabla_W_C_list[l].shape[1]):
                nabla_W_C_list[l][k][j] = delta_list[l][k]*a_list[l-1][j]
    return nabla_W_C_list, nabla_b_C_list
        
def sigma(A):
    return 1/(1+np.exp(-A))

def d_sigma(A):
    sig = sigma(A)
    return sig-sig**2

def update(nabla_W_C_list, nabla_b_C_list, eta):
    for l in range(1,N_layer):
        W_list[l] -= eta*nabla_W_C_list[l]
        b_list[l] -= eta*nabla_b_C_list[l]
    
def shuffle_pairs(x_input,y_input):
    N_input = len(y_input)
    x_output = [None]*N_input
    y_output = [None]*N_input
    data_paired = [None]*N_input
    
    for i in range(0,N_input):
        data_paired[i] = [x_input[i],y_input[i]]

    rd.shuffle(data_paired)
    for i in range(0,N_input):
        x_output[i] = data_paired[i][0]
        y_output[i] = data_paired[i][1]
    return x_output, y_output

def train(eta,N_epochs,N_data_batch,x_train,y_train,x_validation = None,y_validation = None):
    print("Training neural network...")
    N_data_train = len(x_train)
    N_batch = int(np.floor(N_data_train/N_data_batch))
    
    x_batch_list = [None]*N_batch
    y_batch_list = [None]*N_batch
    
    if x_validation:
        plot_y_list = [None]*10
        N_plot_y_list = len(plot_y_list)
        results = validate(x_validation,y_validation)
        for i in range(0,N_plot_y_list):
            plot_y_list[i] = [None]*(N_batch*N_epochs+1)
            plot_y_list[i][0] = results[i]
        
    for i in range(0,N_epochs):
        x_shuffled, y_shuffled = shuffle_pairs(x_train,y_train)
        for j in range(0,N_batch):
            x_batch_list[j] = x_shuffled[j*N_data_batch:(j+1)*N_data_batch]
            y_batch_list[j] = y_shuffled[j*N_data_batch:(j+1)*N_data_batch]
    
        for j in range(0,N_batch):
            print("Epoch: " + str(i+1) + " of " + str(N_epochs) + ", Batch: " + str(j+1) + " of " + str(N_batch))
            x_curr = x_batch_list[j]
            y_curr = y_batch_list[j]
            for k in range(0,N_data_batch):
                nabla_W_C_list, nabla_b_C_list = back_prop(x_curr[k],y_curr[k])
                update(nabla_W_C_list,nabla_b_C_list,eta)
    
            if x_validation:
                y_results = validate(x_validation,y_validation)
                for l in range(0,N_plot_y_list):
                    plot_y_list[l][i*N_batch+j+1] = y_results[l]
    fig = plt.figure()
    ax = fig.add_subplot(1,1,1)
    for i in range(0,N_plot_y_list):
        ax.plot(plot_y_list[i])
    ax.legend(labels=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9' ], loc = "lower left")

def display(x_input,size_output_x, size_output_y):
    x_matrix = np.reshape(x_input,(size_output_x,size_output_y))
    plt.imshow(x_matrix, cmap='gray_r')
    plt.show()

def evaluate(x_input, display_images = ""):
    if (display_images == "Display Images"): 
        display(x_input, size_output_x, size_output_y)
    return np.argmax(feedforward(x_input))

def validate(x_validation, y_validation, show_progress = "", histogram = ""):
    N_data_validation = len(x_validation)
    results = [0]*10
    number_total = [0]*10
    number_correct = [0]*10
    i_correct = 0
    
    if (show_progress == "Show Progress"):
        for i in range(0,N_data_validation):
            y_NN = evaluate(x_validation[i],"Display Images")
            y_val = np.argmax(y_validation[i])
            number_total[y_val] += 1
            if y_NN == y_val:
                number_correct[y_val] +=1
                i_correct += 1
            print("y_NN = " + str(y_NN) + ", y_val = " + str(y_val))
            print("Correct outputs: " + str(int(i_correct)) + " of " + str(int(i+1)) + " processed (" + str(round(100*(i_correct/(i+1)),2)) + "%)" )
            print("Total: " + str(int(N_data_validation)))
        
    else:
        for i in range(0,N_data_validation):
            y_NN = evaluate(x_validation[i])
            y_val = np.argmax(y_validation[i])
            number_total[y_val] +=1
            if y_NN == y_val:
                number_correct[y_val] +=1
                i_correct += 1
        print("Correct outputs: " + str(int(i_correct)) + " of " + str(N_data_validation) + "  (" + str(round(100*(i_correct/(i+1)),2)) + "%)" )
        
    if(histogram == "Histogram"):
        Data_histogram_correct = [0]*10
        Data_histogram_incorrect = [0]*10
        Numbers = ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9"]
        for i in range(0,N_data_validation):
            y_NN = evaluate(x_validation[i])
            y_val = np.argmax(y_validation[i]) 
            if y_NN == y_val:
                Data_histogram_correct[y_val] += 1
            else:
                Data_histogram_incorrect[y_val] += 1 
        fig = plt.figure()
        ax = fig.add_subplot(1,1,1) 
        ax.bar(Numbers, Data_histogram_correct, color = 'b')
        ax.bar(Numbers, Data_histogram_incorrect, bottom = Data_histogram_correct, color = 'r')
        ax.legend(labels=['Correct', 'Incorrect'])
        
        for i in range(0,len(Numbers)):
            print(Numbers[i] + " : " + str(Data_histogram_correct[i]) + " correct estimations of " + str(Data_histogram_correct[i]+ Data_histogram_incorrect[i]) + " (" + str(round(100*(Data_histogram_correct[i]/(Data_histogram_correct[i]+ Data_histogram_incorrect[i])),2)) + "%)")
    

    for i in range(0,10):
        results[i] = round(number_correct[i]/number_total[i],4)
        
    return results         

layer_list = [784,30,10]
N_layer = len(layer_list)

#W_list = [None]*N_layer
#b_list = [None]*N_layer
#for i in range(1,N_layer):
#    W_list[i] = np.round(np.random.randn(layer_list[i],layer_list[i-1]),2)
#    b_list[i] = np.round(np.random.randn(layer_list[i],1),2)

os.chdir('/Users/michelsmacbookpro/Library/Mobile Documents/com~apple~CloudDocs/Written-Calculator/')
W_list_data = np.load("W_list.npy")
b_list_data = np.load("b_list.npy")
W_list = [None]*N_layer
b_list = [None]*N_layer
for i in range(1,N_layer):
    W_list[i] = W_list_data[i]
    b_list[i] = b_list_data[i]

data_training, data_validation, data_test = data_load()
x_training, y_training = data_processing(data_training)
x_validation, y_validation = data_processing(data_validation)
x_test, y_test = data_processing(data_test)

y_training = data_MNIST_vectorize(y_training)
y_validation = data_MNIST_vectorize(y_validation)
y_test = data_MNIST_vectorize(y_test)

#validate(x_validation,y_validation,"Show Progress")
N_epochs = 8
N_data_batch = 20
eta = 1
size_output_x = 28
size_output_y = 28

train(eta,N_epochs,N_data_batch,x_training+x_test,y_training+y_test,x_validation,y_validation)

np.save("W_list.npy",W_list)
np.save("b_list.npy",b_list)

validate(x_validation,y_validation,show_progress = "", histogram = "Histogram")

W_list_list = [None]*(N_layer-1)
b_list_list = [None]*(N_layer-1)
for i in range(1,N_layer):
    W_list_list[i-1]= W_list[i].tolist()
    b_list_list[i-1]= b_list[i].tolist()

with open('your_file.txt', 'w') as f:
    for item in my_list:
        print >> f, item
